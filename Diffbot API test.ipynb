{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York 8.824677891164198: New York: http://dbpedia.org/resource/New_York_(state)\n",
      "Grand Central Terminal 6.396929655216146: Grand Central Terminal: None\n"
     ]
    }
   ],
   "source": [
    "from diffbot_api import *\n",
    "from ttl import *\n",
    "\n",
    "from converter import URIConverter\n",
    "from math import log\n",
    "import json\n",
    "from utils import truncated_log, overlap\n",
    "from candidate import Candidate\n",
    "\n",
    "    \n",
    "phrases = \"New York, windows, catwalk, teardrops, commuters, curved, floor, shape, video, walls, Grand Central Terminal\"\n",
    "phrases =  [Phrase(phrase.strip(), 1, len(phrase.strip()), \"http://\" + phrase.strip())\n",
    "                   for phrase in phrases.split(\",\")]\n",
    "context = \"Inside, itâ€™s even wackier: curved walls, windows in the shape of teardrops, and a catwalk with a tiny video screen embedded in the floor that shows an endless loop of antlike commuters rushing through Grand Central Terminal in New York.\"\n",
    "\n",
    "\n",
    "class BaselineLinker(object):\n",
    "    def __init__(self, use_overlap = True, verbose = True):\n",
    "        self._cq = CachedQuery()\n",
    "        self._conv = URIConverter()\n",
    "        self._use_overlap = use_overlap\n",
    "        self._verbose = verbose\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "    def close(self):\n",
    "        try:\n",
    "            self._cq.close()\n",
    "            self._conv.close()\n",
    "        except:\n",
    "            print(\"Warning: trying to close a closed object.\") \n",
    "    \n",
    "    def find_wiki_uri(self, uris):\n",
    "        for uri in uris:\n",
    "            if \"wikipedia.org\" in uri:\n",
    "                return uri\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_dbpedia_uri(self, candidate):\n",
    "        dbpedia_uri = None\n",
    "        if candidate.wiki is not None:\n",
    "            wiki_uri = candidate.wiki\n",
    "            dbpedia_uri = conv.wikipedia2dbpedia(wiki_uri)\n",
    "        else:\n",
    "            for uri in candidate.uris:\n",
    "                dbpedia_uri = conv.wikidata2dbpedia(uri)\n",
    "                #print(uri, dbpedia_uri)\n",
    "                if dbpedia_uri is not None: break\n",
    "\n",
    "        return dbpedia_uri\n",
    "\n",
    "    def link_db_query(self, target, diffbot_query_response, use_overlap=True):\n",
    "        candidates = []\n",
    "        if \"data\" not in diffbot_query_response:\n",
    "            return candidates\n",
    "        else:\n",
    "            data = diffbot_query_response[\"data\"]\n",
    "\n",
    "        for hit in data:\n",
    "            uris = set(hit[\"allUris\"])\n",
    "            if \"origin\" in hit: uris.add( hit[\"origin\"] )\n",
    "            if \"origins\" in hit: uris.union( set(hit[\"origins\"]) )\n",
    "            if \"wikipediaUri\" in hit:\n",
    "                uris.add( hit[\"wikipediaUri\"] )\n",
    "\n",
    "            if \"importance\" in hit:\n",
    "                name = hit[\"name\"]\n",
    "                importance = float(hit[\"importance\"])\n",
    "                score = truncated_log(importance) * self.overlap(name, target) if use_overlap else importance\n",
    "                c = Candidate(score,\n",
    "                              name,\n",
    "                              find_wiki_uri(uris),\n",
    "                              hit[\"types\"],\n",
    "                              hit[\"allNames\"],\n",
    "                              uris)\n",
    "                candidates.append(c)\n",
    "            else:\n",
    "                print(\"Warning: Skipping a hit without importance value.\")\n",
    "\n",
    "        return sorted(candidates, reverse=True)\n",
    "\n",
    "    def link(self, context, phrases):\n",
    "        best = []\n",
    "        for phrase in phrases:\n",
    "            candidates = []\n",
    "            for entity_type in EL_POL_ENTITY_TYPES:\n",
    "                r = self._cq.make_query('type:{} name:\"{}\"'.format(entity_type, phrase.text))\n",
    "                db_response = json.loads(r.content)\n",
    "                candidates += self.link_db_query(phrase.text, db_response, use_overlap=self._use_overlap) \n",
    "            candidates = set(candidates)\n",
    "\n",
    "            best.append( (phrase, sorted(candidates, reverse=True)[0]) )\n",
    "            dbpedia_uri = get_dbpedia_uri(best)\n",
    "\n",
    "            if self._verbose:\n",
    "                print(\"{} {}: {}: {}\".format(phrase.text, best.score, best.name, dbpedia_uri), end=\"\\n\")\n",
    "\n",
    "        if len(best) != len(phrases):\n",
    "            print(\"Warning: length of output is not equal to length of input {} != {}\".format(len(best), len(phrases)))\n",
    "        \n",
    "        return best\n",
    "    \n",
    "    def link_ttl(self, input_ttl):\n",
    "        graph, context, phrases = parse_d2kb_ttl(input_ttl)\n",
    "\n",
    "        print(\"# triples input:\", len(graph))\n",
    "        for linked_phrase in self.link(context, phrases):\n",
    "            graph.add( (phrase.subj, CLASS_URI, NONE_URI) )\n",
    "            graph.add( (phrase.subj, LINK_URI, NONE_URI) )\n",
    "        \n",
    "        print(\"# triples output:\", len(graph))\n",
    "        output_ttl = str(graph.serialize(format='n3', encoding=\"utf-8\"), \"utf-8\")\n",
    "        return output_ttl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gct\n",
    "russians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_and_save('allUris:\"barackobama.com\"', \"data/all-uris.json\")\n",
    "query_and_save('wikipediaUri:\"en.wikipedia.org/wiki/Barack_Obama\"', \"data/wiki-uri.json\")\n",
    "query_and_save('allUris:\"en.wikipedia.org/wiki/Barack\\_Obama\"', \"data/all-uris-wiki.json\")\n",
    "query_and_save('origins:\"en.wikipedia.org/wiki/Barack_Obama\"', \"data/origins.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for entity_type in entity_types:\n",
    "    query_and_save(\n",
    "        query='type:{}'.format(entity_type),\n",
    "        output_fpath=\"data/{}.json\".format(entity_type))\n",
    "    \n",
    "query_and_save(\n",
    "    query='type:Person name:\"Alexander Panchenko\"',\n",
    "    output_fpath=\"data/ap.json\")\n",
    "\n",
    "\n",
    "query_and_save(\n",
    "    query='type:Person employments.employer.name:\"Diffbot\"',\n",
    "    output_fpath=\"data/diffbot-employees.json\")\n",
    "\n",
    "\n",
    "query_and_save(\n",
    "    query='type:Person employments.{title:\"CEO\" employer.name:\"Diffbot\"}',\n",
    "    output_fpath=\"data/diffbot-ceo.json\")\n",
    "\n",
    "query_and_save(\n",
    "    query='type:Person employments.{employer.name:\"Diffbot\" isCurrent:true}',\n",
    "    output_fpath=\"data/diffbot-current-employees.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing type of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_and_save(\n",
    "    query='type:Person name:\"Angela Merkel\"',\n",
    "    output_fpath=\"data/am.json\")\n",
    "\n",
    "query_and_save(\n",
    "    query='type:Person name:\"Barack Obama\"',\n",
    "    output_fpath=\"data/bo.json\")\n",
    "\n",
    "query_and_save(\n",
    "    query='type:Person name:\"Nicolas Sarkozy\"',\n",
    "    output_fpath=\"data/ns.json\")\n",
    "\n",
    "query_and_save(\n",
    "    query='type:Person name:\"Diego Maradona\"',\n",
    "    output_fpath=\"data/dm.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
